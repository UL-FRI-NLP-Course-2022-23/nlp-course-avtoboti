{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.1.json: 10.3kB [00:00, 5.02MB/s]                   \n",
      "2023-05-25 09:08:53 INFO: Downloading these customized packages for language: sl (Slovenian)...\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| depparse  | standard |\n",
      "| ner       | standard |\n",
      "| pretrain  | standard |\n",
      "========================\n",
      "\n",
      "2023-05-25 09:08:54 INFO: File exists: ../models/classla_resources/sl/pos/standard.pt.\n",
      "2023-05-25 09:08:54 INFO: File exists: ../models/classla_resources/sl/lemma/standard.pt.\n",
      "2023-05-25 09:08:55 INFO: File exists: ../models/classla_resources/sl/depparse/standard.pt.\n",
      "2023-05-25 09:08:55 INFO: File exists: ../models/classla_resources/sl/ner/standard.pt.\n",
      "2023-05-25 09:08:55 INFO: File exists: ../models/classla_resources/sl/pretrain/standard.pt.\n",
      "2023-05-25 09:08:55 INFO: Finished downloading models and saved to ../models/classla_resources.\n"
     ]
    }
   ],
   "source": [
    "from main import read_file, get_sentences\n",
    "import classla\n",
    "classla.download(\"sl\", dir=\"../models/classla_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 09:08:58 INFO: Loading these models for language: sl (Slovenian):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| ner       | standard |\n",
      "========================\n",
      "\n",
      "/home/sebastjan/miniconda3/envs/nlp-course-fri/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370120218/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-05-25 09:08:59 INFO: Use device: cpu\n",
      "2023-05-25 09:08:59 INFO: Loading: tokenize\n",
      "2023-05-25 09:08:59 INFO: Loading: pos\n",
      "2023-05-25 09:09:09 INFO: Loading: lemma\n",
      "2023-05-25 09:09:22 INFO: Loading: ner\n",
      "2023-05-25 09:09:22 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "text = read_file(\"../data/slovenian_short_stories/Vrag_se_ženi.txt\")\n",
    "\n",
    "preprocess = classla.Pipeline(\"sl\", dir=\"../models/classla_resources\", processors=\"tokenize,pos,lemma,ner\")\n",
    "\n",
    "doc = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_named_entities(classla_doc, thresh_perc=0.25):\n",
    "    named_entities_in_doc = []\n",
    "    nouns_in_doc = []\n",
    "    for sentence in classla_doc.sentences:\n",
    "        mention_tokens = []\n",
    "        for token in sentence.tokens:\n",
    "            word = token.words[0]\n",
    "            if len(mention_tokens) > 0 and not token.ner.endswith(\"-PER\"):\n",
    "                named_entities_in_doc.append(\" \".join([w.lemma for t in mention_tokens for w in t.words]))\n",
    "            if token.ner.endswith('-PER'):\n",
    "                mention_tokens.append(token)\n",
    "            elif word.xpos[0] == \"N\":\n",
    "                nouns_in_doc.append(\" \".join([w.lemma for w in token.words]))\n",
    "        if len(mention_tokens) > 0:\n",
    "            named_entities_in_doc.append(\" \".join(mention_tokens))\n",
    "    nelf = dict(Counter(named_entities_in_doc))\n",
    "    nlf = dict(Counter(nouns_in_doc))\n",
    "    nlf_lim = max(nlf.values()) * thresh_perc\n",
    "    nlf = {k: v for k, v in nlf.items() if v > nlf_lim}\n",
    "    return nelf, nlf\n",
    "\n",
    "def find_mention(id, mentions):\n",
    "    for mention in mentions:\n",
    "        if id == mention.mention_id:\n",
    "            return mention\n",
    "    return None\n",
    "\n",
    "def get_relevant_mentions(corefs, ments, ne_candidates):\n",
    "    return {k: vals for k, vals in corefs.items() if \" \".join([t.lemma for t in find_mention(k, ments).tokens]) in ne_candidates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized contextual BERT-based model with name cseb_senticoref_suk.\n",
      "INFO:root:Initialized contextual BERT-based model with name cseb_senticoref_suk.\n"
     ]
    }
   ],
   "source": [
    "from coref.resolve_text import Resolver\n",
    "\n",
    "resolver = Resolver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_mentioned_characters(text):\n",
    "    doc = preprocess(text)\n",
    "    _1, _2 = get_named_entities(doc)\n",
    "    ne_candidates = {**_1, **_2}\n",
    "    coref_output = resolver.coref(doc, ne_candidates, 0.5, 10, 8)\n",
    "    mentions, coreferences = coref_output\n",
    "    relevant_mentions = get_relevant_mentions(coreferences, mentions, ne_candidates)\n",
    "    coref_lemma_counts = {\" \".join([t.lemma for t in find_mention(k, mentions).tokens]): len(v) for k, v in relevant_mentions.items()}\n",
    "    lemma_counts = ne_candidates\n",
    "    for lemma in coref_lemma_counts:\n",
    "        lemma_counts[lemma] += coref_lemma_counts[lemma]\n",
    "    return lemma_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32:42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64:67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'oče': 7,\n",
       " 'hči': 9,\n",
       " 'vrag': 21,\n",
       " 'soba': 10,\n",
       " 'jabolko': 11,\n",
       " 'pekel': 9,\n",
       " 'žena': 10,\n",
       " 'sestra': 10,\n",
       " 'koš': 16,\n",
       " 'hiša': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_mentioned_characters(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n",
      "=====================\n",
      "{'oče': 6, 'hči': 6, 'vrag': 20, 'soba': 9, 'jabolko': 10, 'pekel': 8, 'žena': 8, 'sestra': 9, 'koš': 14, 'hiša': 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[129,\n",
       " 2,\n",
       " 390,\n",
       " 519,\n",
       " 273,\n",
       " 148,\n",
       " 151,\n",
       " None,\n",
       " 183,\n",
       " 56,\n",
       " None,\n",
       " 64,\n",
       " 67,\n",
       " None,\n",
       " None,\n",
       " 466,\n",
       " 367,\n",
       " None,\n",
       " 253,\n",
       " None,\n",
       " 510,\n",
       " 511]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_leading_mention(mentions, cluster, ne_candidates):\n",
    "    print(\"=====================\")\n",
    "    print(ne_candidates)\n",
    "    maxi = -1\n",
    "    maxcount = 0\n",
    "    for i in cluster:\n",
    "        if mentions[i][\"ner_type\"].endswith('-PER'):\n",
    "            lemma = mentions[i][\"lemmas\"][0]\n",
    "            if lemma in ne_candidates:\n",
    "                if ne_candidates[lemma] > maxcount:\n",
    "                    maxi = i\n",
    "                    maxcount = ne_candidates[lemma]\n",
    "    if maxi < 0:\n",
    "        for i in cluster:\n",
    "            lemma = mentions[i][\"lemmas\"][0]\n",
    "            if lemma in ne_candidates:\n",
    "                if ne_candidates[lemma] > maxcount:\n",
    "                    maxi = i\n",
    "                    maxcount = ne_candidates[lemma]\n",
    "\n",
    "    return maxi if maxi >= 0 else None\n",
    "\n",
    "mentions, clusters = coref_output\n",
    "leading_clusters = list(map(lambda x: get_leading_mention(mentions, x, ne_candidates), clusters))\n",
    "leading_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 18:16:38 INFO: Loading these models for language: sl (Slovenian):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| ner       | standard |\n",
      "========================\n",
      "\n",
      "2023-04-26 18:16:38 INFO: Use device: cpu\n",
      "2023-04-26 18:16:38 INFO: Loading: tokenize\n",
      "2023-04-26 18:16:38 INFO: Loading: pos\n",
      "2023-04-26 18:16:52 INFO: Loading: lemma\n",
      "2023-04-26 18:17:06 INFO: Loading: ner\n",
      "2023-04-26 18:17:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from main import get_named_entities\n",
    "from collections import Counter\n",
    "from main import read_file, get_sentences\n",
    "import classla\n",
    "\n",
    "preprocess = classla.Pipeline(\"sl\", dir=\"../models/classla_resources\", processors=\"tokenize,pos,lemma,ner\")\n",
    "\n",
    "def get_most_mentioned_characters(raw_text):\n",
    "    # tokenize, pos, lemma, ner\n",
    "    doc_ne = preprocess(raw_text)\n",
    "\n",
    "    # extract only NE with PERSON tag\n",
    "    named_entities = get_named_entities(doc_ne, lang='sl')\n",
    "    names = []\n",
    "    for ne in named_entities:\n",
    "        for named_entity in ne:\n",
    "            names.append(named_entity.to_dict()[0]['lemma'])\n",
    "\n",
    "    # count frequencies of each name and sort them\n",
    "    name_frequencies = Counter(names)\n",
    "    name_frequencies = {k:v for (k,v) in sorted(name_frequencies.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    return name_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating a single document...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0-0', '0-1', '0-2', '0-3', '0-4', '0-5', '0-6', '0-7', '0-8', '0-9', '0-10', '0-11'], ['1-0', '1-1', '1-2', '1-3', '1-4', '1-5', '1-6', '1-7', '1-8', '1-9', '1-10', '1-11', '1-12', '1-13'], ['2-0', '2-1', '2-2', '2-3', '2-4', '2-5', '2-6', '2-7', '2-8', '2-9', '2-10', '2-11', '2-12', '2-13', '2-14', '2-15', '2-16', '2-17', '2-18', '2-19', '2-20', '2-21', '2-22', '2-23']]\n",
      "{1: <coref.data.Mention object at 0x7f3beeb54190>, 2: <coref.data.Mention object at 0x7f3beeb54100>, 3: <coref.data.Mention object at 0x7f3beeb54a60>, 4: <coref.data.Mention object at 0x7f3beeabcfa0>, 5: <coref.data.Mention object at 0x7f3beeabd030>, 6: <coref.data.Mention object at 0x7f3beeabd120>, 7: <coref.data.Mention object at 0x7f3beeabd1e0>, 8: <coref.data.Mention object at 0x7f3beeabd2a0>, 9: <coref.data.Mention object at 0x7f3beeabd420>, 10: <coref.data.Mention object at 0x7f3beeabd4e0>, 11: <coref.data.Mention object at 0x7f3beeabd5d0>, 12: <coref.data.Mention object at 0x7f3beeabd660>, 13: <coref.data.Mention object at 0x7f3beeabd6c0>, 14: <coref.data.Mention object at 0x7f3beeabd750>, 15: <coref.data.Mention object at 0x7f3beeabd7e0>, 16: <coref.data.Mention object at 0x7f3beeabd8a0>, 17: <coref.data.Mention object at 0x7f3beeabd990>, 18: <coref.data.Mention object at 0x7f3beeabda80>, 19: <coref.data.Mention object at 0x7f3beeabdb10>, 20: <coref.data.Mention object at 0x7f3beeabdba0>, 21: <coref.data.Mention object at 0x7f3beeabdc90>, 22: <coref.data.Mention object at 0x7f3beeabdd50>, 23: <coref.data.Mention object at 0x7f3beeabde10>}\n",
      "----------\n",
      "{'predictions': {None: [1, 5], 1: [2, 6], 2: [3, 16], 3: [4], 6: [7, 11], 7: [8], 8: [9], 9: [10], 11: [12], 12: [13, 14], 13: [15, 23], 16: [17], 17: [18], 5: [19], 18: [20, 22], 19: [21]}, 'clusters': {1: 0, 6: 0, 11: 0, 12: 0, 14: 0, 13: 0, 23: 0, 15: 0, 7: 0, 8: 0, 9: 0, 10: 0, 2: 0, 16: 0, 17: 0, 18: 0, 22: 0, 20: 0, 3: 0, 4: 0, 5: 1, 19: 1, 21: 1}, 'scores': {1: 1, 6: 0.46057483553886414, 11: 0.18268832564353943, 12: 0.12285177409648895, 14: 0.11539792269468307, 13: 0.12677128612995148, 23: 0.18064942955970764, 15: 0.13948164880275726, 7: 0.3350539207458496, 8: 0.18722514808177948, 9: 0.1699426919221878, 10: 0.46959739923477173, 2: 0.9753801822662354, 16: 0.1312076598405838, 17: 0.09407969564199448, 18: 0.10416214168071747, 22: 0.10127108544111252, 20: 0.1343947947025299, 3: 0.6692712306976318, 4: 0.4630799889564514, 5: 0.988642156124115, 19: 0.181597039103508, 21: 0.2497197538614273}}\n",
      "Resolving coreference sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'id': 1,\n",
       "   'start_idx': 0,\n",
       "   'length': 8,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-p-dm',\n",
       "   'text': 'Bila sta'},\n",
       "  {'id': 2,\n",
       "   'start_idx': 9,\n",
       "   'length': 3,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncmsn',\n",
       "   'text': 'oče'},\n",
       "  {'id': 3,\n",
       "   'start_idx': 16,\n",
       "   'length': 4,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncfsn',\n",
       "   'text': 'mati'},\n",
       "  {'id': 4,\n",
       "   'start_idx': 25,\n",
       "   'length': 9,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-r3d-n',\n",
       "   'text': 'sta imela'},\n",
       "  {'id': 5,\n",
       "   'start_idx': 39,\n",
       "   'length': 5,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncfpa',\n",
       "   'text': 'hčere'},\n",
       "  {'id': 6,\n",
       "   'start_idx': 46,\n",
       "   'length': 7,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncfsn',\n",
       "   'text': 'Nesreča'},\n",
       "  {'id': 7,\n",
       "   'start_idx': 57,\n",
       "   'length': 9,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-r3s-n',\n",
       "   'text': 'je hotela'},\n",
       "  {'id': 8,\n",
       "   'start_idx': 71,\n",
       "   'length': 6,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Px------y',\n",
       "   'text': 'se jim'},\n",
       "  {'id': 9,\n",
       "   'start_idx': 78,\n",
       "   'length': 12,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-r3s-y',\n",
       "   'text': 'ni približal'},\n",
       "  {'id': 10,\n",
       "   'start_idx': 99,\n",
       "   'length': 5,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncmsn',\n",
       "   'text': 'ženin'},\n",
       "  {'id': 11,\n",
       "   'start_idx': 106,\n",
       "   'length': 2,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Pd-nsn',\n",
       "   'text': 'To'},\n",
       "  {'id': 12,\n",
       "   'start_idx': 109,\n",
       "   'length': 2,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-r3s-n',\n",
       "   'text': 'je'},\n",
       "  {'id': 13,\n",
       "   'start_idx': 112,\n",
       "   'length': 5,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Rgp',\n",
       "   'text': 'močno'},\n",
       "  {'id': 14,\n",
       "   'start_idx': 118,\n",
       "   'length': 6,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Vmpp-sn',\n",
       "   'text': 'jezilo'},\n",
       "  {'id': 15,\n",
       "   'start_idx': 125,\n",
       "   'length': 5,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncfsa',\n",
       "   'text': 'mater'},\n",
       "  {'id': 16,\n",
       "   'start_idx': 132,\n",
       "   'length': 3,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncmsn',\n",
       "   'text': 'oče'},\n",
       "  {'id': 17,\n",
       "   'start_idx': 139,\n",
       "   'length': 8,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Va-r3s-n',\n",
       "   'text': 'je rekel'},\n",
       "  {'id': 18,\n",
       "   'start_idx': 150,\n",
       "   'length': 5,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Vmpr1s-n',\n",
       "   'text': 'Hočem'},\n",
       "  {'id': 19,\n",
       "   'start_idx': 156,\n",
       "   'length': 3,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Pp3mpa--y',\n",
       "   'text': 'jih'},\n",
       "  {'id': 20,\n",
       "   'start_idx': 160,\n",
       "   'length': 7,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Vmen',\n",
       "   'text': 'omožiti'},\n",
       "  {'id': 21,\n",
       "   'start_idx': 172,\n",
       "   'length': 3,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Pp3mpa--y',\n",
       "   'text': 'jih'},\n",
       "  {'id': 22,\n",
       "   'start_idx': 176,\n",
       "   'length': 9,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Vmpr1s-n',\n",
       "   'text': 'imam dati'},\n",
       "  {'id': 23,\n",
       "   'start_idx': 193,\n",
       "   'length': 6,\n",
       "   'ner_type': 'O',\n",
       "   'msd': 'Ncmsd',\n",
       "   'text': 'hudiču'}],\n",
       " [[1, 2, 3, 4, 6, 7], [9, 10]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from coref.run_model import coref_resolution, get_slocoref\n",
    "\n",
    "vrag = read_file(\"../data/slovenian_short_stories/Vrag_se_ženi.txt\")\n",
    "# doc = preprocess(\"\"\"Bila sta oče in mati, ki sta imela tri hčere. Nesreča pa je hotela, da se jim ni približal niti en ženin. To je močno jezilo mater, oče pa je rekel: »Hočem jih omožiti, če jih imam dati samemu hudiču!«\n",
    "\n",
    "# Vrag je bil takoj pripravljen, da ugrabi tri duše. Računal pa je na žensko radovednost. Napravljen kot grof je prišel k očetu in ga zaprosil za starejšo hčer. Z velikim veseljem mu jo je dal, češ: če je ne dam takemu gospodu, komu pak?! Vrag jo je odpeljal v neki navidezen grad in ji rekel: »Drugega opravila nimaš, kot da nosiš iz sobe v sobo tole zlato jabolko, le v dvanajsto sobo ne smeš pogledati!« Ona vzame zlato jabolko ter teka po gradu iz sobe v sobo. Pride do vrat dvanajste sobe; tu postoji in si misli: Kaj neki bi bilo, četudi pogledam? Do zdaj je bila vsaka soba lepša, in kdo ve, kaj je šele v tej? Radovednost jo premaga, odpre in zagleda pekel, kako vragi mučijo uboge duše. Zlato jabolko pa ji je padlo v pekel, kjer je zgorelo. Vsa zmučena zapre vrata in teče proč. Tedaj jo sreča njen mož – vrag. »Kje je jabolko?« zavpije in pahne še njo v peklensko brezno.\"\"\")\n",
    "\n",
    "doc = preprocess(\"Bila sta oče in mati, ki sta imela tri hčere. Nesreča pa je hotela, da se jim ni približal niti en ženin. To je močno jezilo mater, oče pa je rekel: »Hočem jih omožiti, če jih imam dati samemu hudiču!«\")\n",
    "\n",
    "# Requires \"tokenize,pos,lemma,ner\" preprocessors\n",
    "# coref_output = coref_resolution(doc, 0.1, False, window_size=10, window_stride=8)\n",
    "coref_output = coref_resolution(doc, 0.3, False)\n",
    "\n",
    "coref_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'start_idx': 0, 'length': 8, 'ner_type': 'O', 'msd': 'Va-p-dm', 'text': 'Bila sta'}\n",
      "{'id': 2, 'start_idx': 9, 'length': 3, 'ner_type': 'O', 'msd': 'Ncmsn', 'text': 'oče'}\n",
      "{'id': 3, 'start_idx': 16, 'length': 4, 'ner_type': 'O', 'msd': 'Ncfsn', 'text': 'mati'}\n",
      "{'id': 4, 'start_idx': 25, 'length': 9, 'ner_type': 'O', 'msd': 'Va-r3d-n', 'text': 'sta imela'}\n",
      "{'id': 6, 'start_idx': 46, 'length': 7, 'ner_type': 'O', 'msd': 'Ncfsn', 'text': 'Nesreča'}\n",
      "{'id': 7, 'start_idx': 57, 'length': 9, 'ner_type': 'O', 'msd': 'Va-r3s-n', 'text': 'je hotela'}\n"
     ]
    }
   ],
   "source": [
    "mentions = coref_output[0]\n",
    "clusters = coref_output[1]\n",
    "for mention in clusters[0]:\n",
    "    print(mentions[mention - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
